---
title: "helen.ASV.level.var"
author: "Helen Casendino"
date: "8/13/2021"
output: html_document
---

This code is the same as helen.ASV.level.var.Rmd, but it looks at eDNA INDICES rather than PROPORTIONS, and only looks at PCR TRIPLICATES. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r dependencies, include=FALSE}
library(tidyverse)
library(gridExtra)
library(stringi)
```

# Part A. ASV Variation within Technical Replicates

## Description: 

  1) Starting with triplicate PCR reads that have seriously low reads excluded, I'll get a standard deviation across PCR reps for each Hash. Hashes in different bio reps are kept separate. 
  2) Then, I'll loop through different eDNA index cutoffs (averaging index values across PCR reps for each hash), each time calculating the LOGNORMAL mean of all of the standard deviations (across bio reps, etc.)

```{r read in clean triplicate data}
trip.index <- read.csv('../data/PCR.index.clean.csv')
```

1) 
```{r standard deviation of each Hash}
SD.across.rows <- function(df, col.numbers){ # here, col.numbers corresponds to 3 PCR columns
  df$StanDev <- NA
  values.only <- df[,col.numbers]
  df$StanDev <- apply(values.only, MARGIN = 1, sd, na.rm=TRUE) #joe added na.rm=TRUE

  return(df)
}

SD.tech.output <- SD.across.rows(trip.index, c(3:5))
```

2)
Now, I'll do the same but with different hash rarity cutoffs. This involves:
  - ranking the hashes by average index value across PCR reps
  - chopping some hashes
  - calculating the standard deviation of each remaining hash across PCR replicates
  - keeping track of the mean, and the distribution of SDs for each cutoff to check distribution
  - for eDNA indices, SDs shouldn't be as spread out, won't use lognormal dist

```{r standard deviation of each Hash with cutoff}
SDcutoffs.index <- function(df, cutoffs){
  
  means <- data.frame(cutoffs = cutoffs, means = rep(NA, length(cutoffs)), exclprop =rep(NA, length(cutoffs)))

  SD.dists <- matrix(NA, ncol=length(cutoffs), nrow=length(df$Hash),length(cutoffs)) 
  
     meanIndex.acrossPCR <- df %>% 
       group_by(Hash) %>% 
       summarise(meanIndex.PCR = mean(c(PCR1_index, PCR2_index,PCR3_index))) %>% 
       arrange(desc(meanIndex.PCR)) # to get rarity order
    
    for(i in 1:length(cutoffs)){
      sub.tib <- meanIndex.acrossPCR %>% 
        filter(meanIndex.PCR > cutoffs[i]) # chop hashes below proportion cutoff
    
      means[i,3] <- 1 - (length(sub.tib$Hash)/length(meanIndex.acrossPCR$Hash)) # column 3 is proportion of UNIQUE hashes excluded
      
      PCR.tib <- df %>% 
        filter(Hash %in% sub.tib$Hash) %>% 
        select(!c(Hash, bio)) # all PCR props corresponding to remaining hashes
      
     PCR.SD.tib <- SD.across.rows(PCR.tib, c(1:3))
     SD.dists[1:length(PCR.SD.tib$StanDev),i] <- PCR.SD.tib$StanDev
     
     means[i,2]  <- mean(PCR.SD.tib$StanDev)
  
   print(i) # progress bar
  }
     return(list(means, SD.dists))
}
```

```{r get output}
output<- SDcutoffs.index(trip.index,seq(0, 0.25, 0.01))

# check the distributions for SDs of each cutoff...a few are a little asymmetrical (also loop crashes sometimes depending on how large cutoff sequence so beware)
for(i in 1:length(seq(0, 0.25, 0.01))){
  hist(output[[2]][,i])
}
```

Now let's plot to see how average SD between PCR replicates changed between  cutoffs.

```{r Plotting output}
# 1) Plot mean variability vs. cutoff
SDvsCutoff.plot <-  ggplot() +  theme_minimal() + geom_line(mapping = aes(x = output[[1]][,1], y = output[[1]][,2]), size = .5, color = "red3") + theme(legend.position = "none") + theme(axis.title.y = element_text(color = "red3")) + scale_y_continuous(name = "Mean SD Across PCRs") + xlab("Cutoff") 

# 2) Plot percent of unique hashes chopped vs. cutoff
ChoppedvsCutoff.plot <-  ggplot() +  theme_minimal() + geom_line(mapping = aes(x = output[[1]][,1], y = output[[1]][,3]*100), size = .5, color = "darkmagenta") + theme(legend.position = "none") + theme(axis.title.y = element_text(color = "darkmagenta")) + scale_y_continuous(name = "% Unique Hashes Removed") + xlab("Cutoff")

grid.arrange(SDvsCutoff.plot,ChoppedvsCutoff.plot, nrow=1)
```

# Part B. ASV Variation within Biological Replicates 

## Description:
  - Main goal of code below is to get distribution & mean of ASV variation within Biological and PCR replicates combined, and subtract PCR variation to isolate bio variation
  - The code below creates a nested df where each table belongs to a certain sample (eg, PO20170311)
  - Each table has columns corresponding to every bottle/PCR combination (A.1, B.1, C.2, C.3, etc) and rows corresponding to each ASV found. Values = proportions within a specific bottle
  -Take the standard deviations of each ASV's proportions (across different bio.PCRs, 9x for the most part)
  - End up with a single distribution of SDs for each distinct sampling event

```{r Data Organization: dataset specific}
long.index <- trip.index %>% 
  mutate(sample = gsub('.{1}$', '', bio)) %>% 
  mutate(bottle = stri_sub(bio,-1)) %>% 
  pivot_longer(cols = c(PCR1_index,PCR2_index,PCR3_index), names_to = "PCR", values_to = "Index")

get.PCRn <- long.index %>% 
  mutate("PCRn" = stri_sub(PCR,4,-7)) %>% 
  select(-c(bio,PCR))

nested.indices <- get.PCRn %>% 
  unite(bottle, PCRn, col = "bio.PCR", sep = ".") %>% 
  nest(data = c(bio.PCR,Hash,Index))
```

Now I want to convert each sample's df to have columns for each bio.PCR ID

```{r Widen data so that bio.PCRs are columns}
for(i in 1:length(nested.indices$sample)) {
  
  nested.indices$data[[i]] <- nested.indices$data[[i]] %>% 
    group_by(bio.PCR,Hash) %>% 
    summarise(Index = mean(Index)) %>%  
    pivot_wider(names_from = bio.PCR, values_from= Index, values_fill = 0) 
    
    print(i)
}
# not actually averaging anything, pivot_wider just gets confused about duplicate rows so need for explicit code distinguishing each row 
```

Make and run function that gets SDs across bio.PCRs for each ASV within a sample (uses function from above, SD.across.rows()). Output is all SDs for each bio.PCR.Hash combination

```{r Getting SD dist function and output}
# list = list of n dataframes (n = # of samples). Each dataframe's 1st col is Hash IDs, and all other columns are bio.PCRs (A.2, B.1, etc.) Values are proportions of each Hash within its respective bottle & PCR
# nSamples are the number of distinct samples (ex,PO20170311)

SD.by.BioPCR <- function(list, nSamples){
  
  SDs <- c("start")
  
  for(i in 1:nSamples){
    SD.output <- SD.across.rows(list[[i]], c(2:dim(list[[i]])[2]))#2nd argument = all columns after hash column 
     SDs[(length(SDs) + 1):(length(SD.output$StanDev) + length(SDs))] <- SD.output$StanDev
     print(i)
  }
  return(SDs)
}

SD.bio.tech.output<- SD.by.BioPCR(nested.indices$data, length(nested.indices$sample))

# clean up output
SD.bio.tech.output <- as.numeric(SD.bio.tech.output[-1])

hist(SD.bio.tech.output, col = "red", main = "Distribution of SDs with No Exclusions", xlab = "Index Cutoff")
```
