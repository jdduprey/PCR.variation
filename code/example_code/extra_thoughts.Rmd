---
title: "extra_thoughts"
author: "Kai Vennemann"
date: "11/15/2021"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Some experimentation with our data sets and thoughts

```{r dependencies, include = FALSE}
library(tidyverse)
```

```{r load in data}
df <- as.tibble(read.csv("../../data/long_PCR_props.csv"))
```

```{r analysis of reads}
head(df)
reads_by_tech <- df %>% 
  count(bio, tech, wt = reads)
print(reads_by_tech)

sums <- reads_by_tech$n
print(paste("Min:", min(sums), sep = " "))
print(paste("Max:", max(sums), sep = " "))
print(paste("Standard deviation:", sd(sums), sep = " "))
```

The total number of reads from each technical replicate varies *massively*. For this reason, it seems unlikely that comparing absolute reads across different PCRs will yield usable results. Proportionate data is more promising. However, it might be prudent to remove extremely low read PCRs nonetheless.
